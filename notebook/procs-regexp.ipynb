{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⊕ [6.2. re — Regular expression operations — Python 3.6.8 documentation](https://docs.python.org/3.6/library/re.html#finding-all-adverbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T19:22:00.703659Z",
     "start_time": "2019-04-18T19:22:00.685172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carefully', 'quickly']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"He was carefully disguised but captured quickly by police.\"\n",
    "re.findall(r\"\\w+ly\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:05:51.321634Z",
     "start_time": "2019-04-18T20:05:51.313656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-16: carefully\n",
      "40-47: quickly\n"
     ]
    }
   ],
   "source": [
    "# Finding all Adverbs and their Positions¶\n",
    "text = \"He was carefully disguised but captured quickly by police.\"\n",
    "for m in re.finditer(r\"\\w+ly\", text):\n",
    "    print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:06:36.940219Z",
     "start_time": "2019-04-18T20:06:36.865403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='IF', value='IF', line=2, column=4)\n",
      "Token(type='ID', value='quantity', line=2, column=7)\n",
      "Token(type='THEN', value='THEN', line=2, column=16)\n",
      "Token(type='ID', value='total', line=3, column=8)\n",
      "Token(type='ASSIGN', value=':=', line=3, column=14)\n",
      "Token(type='ID', value='total', line=3, column=17)\n",
      "Token(type='OP', value='+', line=3, column=23)\n",
      "Token(type='ID', value='price', line=3, column=25)\n",
      "Token(type='OP', value='*', line=3, column=31)\n",
      "Token(type='ID', value='quantity', line=3, column=33)\n",
      "Token(type='END', value=';', line=3, column=41)\n",
      "Token(type='ID', value='tax', line=4, column=8)\n",
      "Token(type='ASSIGN', value=':=', line=4, column=12)\n",
      "Token(type='ID', value='price', line=4, column=15)\n",
      "Token(type='OP', value='*', line=4, column=21)\n",
      "Token(type='NUMBER', value=0.05, line=4, column=23)\n",
      "Token(type='END', value=';', line=4, column=27)\n",
      "Token(type='ENDIF', value='ENDIF', line=5, column=4)\n",
      "Token(type='END', value=';', line=5, column=9)\n"
     ]
    }
   ],
   "source": [
    "# A tokenizer or scanner analyzes a string to categorize groups of characters. This is a useful first step in writing a compiler or interpreter.\n",
    "\n",
    "import collections\n",
    "import re\n",
    "\n",
    "Token = collections.namedtuple('Token', ['type', 'value', 'line', 'column'])\n",
    "\n",
    "def tokenize(code):\n",
    "    keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}\n",
    "    token_specification = [\n",
    "        ('NUMBER',   r'\\d+(\\.\\d*)?'),  # Integer or decimal number\n",
    "        ('ASSIGN',   r':='),           # Assignment operator\n",
    "        ('END',      r';'),            # Statement terminator\n",
    "        ('ID',       r'[A-Za-z]+'),    # Identifiers\n",
    "        ('OP',       r'[+\\-*/]'),      # Arithmetic operators\n",
    "        ('NEWLINE',  r'\\n'),           # Line endings\n",
    "        ('SKIP',     r'[ \\t]+'),       # Skip over spaces and tabs\n",
    "        ('MISMATCH', r'.'),            # Any other character\n",
    "    ]\n",
    "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
    "    line_num = 1\n",
    "    line_start = 0\n",
    "    for mo in re.finditer(tok_regex, code):\n",
    "        kind = mo.lastgroup\n",
    "        value = mo.group()\n",
    "        column = mo.start() - line_start\n",
    "        if kind == 'NUMBER':\n",
    "            value = float(value) if '.' in value else int(value)\n",
    "        elif kind == 'ID' and value in keywords:\n",
    "            kind = value\n",
    "        elif kind == 'NEWLINE':\n",
    "            line_start = mo.end()\n",
    "            line_num += 1\n",
    "            continue\n",
    "        elif kind == 'SKIP':\n",
    "            continue\n",
    "        elif kind == 'MISMATCH':\n",
    "            raise RuntimeError(f'{value!r} unexpected on line {line_num}')\n",
    "        yield Token(kind, value, line_num, column)\n",
    "\n",
    "statements = '''\n",
    "    IF quantity THEN\n",
    "        total := total + price * quantity;\n",
    "        tax := price * 0.05;\n",
    "    ENDIF;\n",
    "'''\n",
    "\n",
    "for token in tokenize(statements):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:08:03.130940Z",
     "start_time": "2019-04-18T20:08:03.121204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porfsesor Abomalledk, pslaee rrepot yuor ascneebs ptmlpory.\n",
      "Pseoosrfr Aaledlbmok, psleae rpoert your acenbess potrlmpy.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Text Munging\n",
    "# sub() replaces every occurrence of a pattern with a string or the result of a function. This example demonstrates using sub() with a function to “munge” text, or randomize the order of all the characters in each word of a sentence except for the first and last characters:\n",
    "def repl(m):\n",
    "    inner_word = list(m.group(2))\n",
    "    random.shuffle(inner_word)\n",
    "    return m.group(1) + \"\".join(inner_word) + m.group(3)\n",
    "text = \"Professor Abdolmalek, please report your absences promptly.\"\n",
    "print(re.sub(r\"(\\w)(\\w+)(\\w)\", repl, text))\n",
    "print(re.sub(r\"(\\w)(\\w+)(\\w)\", repl, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:08:47.963897Z",
     "start_time": "2019-04-18T20:08:47.956274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ross McFluff: 834.345.1254 155 Elm Street',\n",
       " 'Ronald Heathmore: 892.345.3428 436 Finley Avenue',\n",
       " 'Frank Burger: 925.541.7625 662 South Dogwood Way',\n",
       " 'Heather Albrecht: 548.326.4584 919 Park Place']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> text = \"\"\"Ross McFluff: 834.345.1254 155 Elm Street\n",
    "...\n",
    "... Ronald Heathmore: 892.345.3428 436 Finley Avenue\n",
    "... Frank Burger: 925.541.7625 662 South Dogwood Way\n",
    "...\n",
    "...\n",
    "... Heather Albrecht: 548.326.4584 919 Park Place\"\"\"\n",
    ">>> entries = re.split(\"\\n+\", text)\n",
    ">>> entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T20:09:34.432574Z",
     "start_time": "2019-04-18T20:09:34.424204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(2, 3), match='c'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> re.match(\"c\", \"abcdef\")    # No match\n",
    ">>> re.search(\"c\", \"abcdef\")   # Match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
