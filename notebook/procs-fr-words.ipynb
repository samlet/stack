{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:35:23.429018Z",
     "start_time": "2019-06-23T14:35:23.397333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strategiques\n",
      "m\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "######################################################################\n",
    "# The files are all in Unicode, to simplify we will turn Unicode\n",
    "# characters to ASCII, make everything lowercase, and trim most\n",
    "# punctuation.\n",
    "#\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"([.!?])\", r\"\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "print(normalizeString('stratégiques'))\n",
    "print(normalizeString('m.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:45:17.580673Z",
     "start_time": "2019-06-23T13:45:17.572277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x x\n",
      "bank \n",
      " \n",
      "likewise\n"
     ]
    }
   ],
   "source": [
    "print(normalizeString('xœx'))\n",
    "# bank@@\n",
    "print(normalizeString('bank@@'))\n",
    "# を@@\n",
    "print(normalizeString('を@@'))\n",
    "# Likewise\n",
    "print(normalizeString('Likewise'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:14:26.648464Z",
     "start_time": "2019-06-23T14:14:26.636507Z"
    }
   },
   "outputs": [],
   "source": [
    "datafile='./data/vocs/fr_samples.txt'\n",
    "# Read the file and split into lines\n",
    "lines = open(datafile, encoding='utf-8').\\\n",
    "    read().strip().split('\\n')\n",
    "# Split every line into pairs and normalize\n",
    "words=[l.split(' ')[0] for l in lines]\n",
    "pairs = [(normalizeString(w),w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:48:04.178938Z",
     "start_time": "2019-06-23T14:48:04.136110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 46\n",
      "qu apos  ➺ qu&apos;\n",
      "les ➺ Les\n",
      "ete ➺ été\n",
      "la ➺ La\n",
      "etre ➺ être\n",
      "s apos  ➺ s&apos;\n",
      "canada ➺ Canada\n",
      "n apos  ➺ n&apos;\n",
      "l apos  ➺ L&apos;\n",
      "autres ➺ autres\n",
      "il ➺ Il\n",
      "cette ➺ cette\n",
      "comme ➺ comme\n",
      "entre ➺ entre\n",
      "developpement ➺ développement\n",
      "en ➺ En\n",
      "conseil ➺ Conseil\n",
      "etats ➺ États\n",
      "droits ➺ droits\n",
      "rapport ➺ rapport\n",
      "services ➺ services\n",
      "commission ➺ Commission\n",
      "travail ➺ travail\n",
      "ainsi ➺ ainsi\n",
      "leurs ➺ leurs\n",
      "egalement ➺ également\n",
      "faire ➺ faire\n",
      "comite ➺ Comité\n",
      "membres ➺ membres\n",
      "securite ➺ sécurité\n",
      "meme ➺ même\n",
      "article ➺ article\n",
      "sante ➺ santé\n",
      "activites ➺ activités\n",
      "nations ➺ Nations\n",
      "droit ➺ droit\n",
      "projet ➺ projet\n",
      "programme ➺ programme\n",
      "aussi ➺ aussi\n",
      "unies ➺ Unies\n",
      "mesures ➺ mesures\n",
      "a ➺ A\n",
      "cadre ➺ cadre\n",
      "personnes ➺ personnes\n",
      "contre ➺ contre\n",
      "e ➺ é\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH=250\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):    \n",
    "    if '@@' in p[1]:\n",
    "        return False\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    if len(p[0]) < MAX_LENGTH and len(p[0].strip())>0:\n",
    "        if len(p[0])<5:\n",
    "            return p[0]!=p[1] \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "pairs = filterPairs(pairs)\n",
    "print('total:', len(pairs))\n",
    "for pair in pairs:\n",
    "    print(pair[0], '➺', pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:21:04.977607Z",
     "start_time": "2019-06-23T14:21:04.970512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aus pers napo\n"
     ]
    }
   ],
   "source": [
    "def shortcut(word):\n",
    "    return word.replace(' ','')[:4]\n",
    "print(shortcut('aus'), shortcut('personnes'), shortcut('n apos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:25:11.643451Z",
     "start_time": "2019-06-23T14:25:11.392325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quap ➺ qu&apos;\n",
      "les ➺ Les\n",
      "ete ➺ été\n",
      "la ➺ La\n",
      "etre ➺ être\n",
      "sapo ➺ s&apos;\n",
      "cana ➺ Canada\n",
      "napo ➺ n&apos;\n",
      "lapo ➺ L&apos;\n",
      "autr ➺ autres\n",
      "il ➺ Il\n",
      "cett ➺ cette\n",
      "comm ➺ comme\n",
      "entr ➺ entre\n",
      "deve ➺ développement\n",
      "en ➺ En\n",
      "cons ➺ Conseil\n",
      "etat ➺ États\n",
      "droi ➺ droits\n",
      "rapp ➺ rapport\n",
      "serv ➺ services\n",
      "comm ➺ Commission\n",
      "trav ➺ travail\n",
      "ains ➺ ainsi\n",
      "leur ➺ leurs\n",
      "egal ➺ également\n",
      "fair ➺ faire\n",
      "comi ➺ Comité\n",
      "memb ➺ membres\n",
      "secu ➺ sécurité\n",
      "meme ➺ même\n",
      "arti ➺ article\n",
      "sant ➺ santé\n",
      "acti ➺ activités\n",
      "nati ➺ Nations\n",
      "droi ➺ droit\n",
      "proj ➺ projet\n",
      "prog ➺ programme\n",
      "auss ➺ aussi\n",
      "unie ➺ Unies\n",
      "mesu ➺ mesures\n",
      "a ➺ A\n",
      "cadr ➺ cadre\n",
      "pers ➺ personnes\n",
      "cont ➺ contre\n",
      "e ➺ é\n"
     ]
    }
   ],
   "source": [
    "import clipboard\n",
    "rs=[]\n",
    "for pair in pairs:\n",
    "    abbr=shortcut(pair[0])\n",
    "    print(abbr, '➺', pair[1])\n",
    "    rs.append('%s %s'%(abbr, pair[1]))\n",
    "clipboard.copy('\\n'.join(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:48:15.533006Z",
     "start_time": "2019-06-23T14:48:15.155128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 25623\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "path='/pi/ai/fairseq/data-bin/wmt14.en-fr.newstest2014/dict.fr.txt'\n",
    "\n",
    "def load_words(file):\n",
    "    # Read the file and split into lines\n",
    "    lines = open(file, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    words=[l.split(' ')[0] for l in lines]\n",
    "    pairs = [(normalizeString(w),w) for w in words]\n",
    "    pairs = filterPairs(pairs)\n",
    "    print('total:', len(pairs))\n",
    "    rs=[]\n",
    "    for pair in pairs:\n",
    "        # if len(pair[0])>1:\n",
    "        abbr=shortcut(pair[0])\n",
    "        # print(abbr, '➺', pair[1])\n",
    "        rs.append('%s %s'%(abbr, pair[1]))\n",
    "    clipboard.copy('\\n'.join(rs))\n",
    "    print('done')\n",
    "\n",
    "load_words(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T16:55:55.896302Z",
     "start_time": "2019-06-23T16:55:55.549769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 23505\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "path='/pi/ai/fairseq/data-bin/wmt14.en-de.newstest2014/dict.de.txt'\n",
    "load_words(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
