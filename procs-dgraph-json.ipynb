{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:00:16.800135Z",
     "start_time": "2019-05-31T07:00:15.414084Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagas.graph.dgraph_helper as helper\n",
    "import pydgraph\n",
    "client=helper.reset('''\n",
    "    name: string @index(exact, term) .\n",
    "    rated: uid @reverse @count .\n",
    "    title: string @lang .\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:00:18.237789Z",
     "start_time": "2019-05-31T07:00:18.188733Z"
    }
   },
   "outputs": [],
   "source": [
    "import json_utils\n",
    "feed_json=json_utils.read_json_file('data/graph/alice.json')\n",
    "_=helper.set_json(client, feed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:01:13.446444Z",
     "start_time": "2019-05-31T07:01:13.422655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"name\": \"Alice\",\n",
      "      \"car|since\": \"2006-02-02T13:02:09Z\",\n",
      "      \"car\": \"MA0123\",\n",
      "      \"friend\": [\n",
      "        {\n",
      "          \"name\": \"Bob\",\n",
      "          \"car|since\": \"2006-02-02T13:01:09Z\",\n",
      "          \"car\": \"MA0134\",\n",
      "          \"title@ru\": \"Russian\",\n",
      "          \"friend|close\": true,\n",
      "          \"friend|relative\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Charlie\",\n",
      "          \"title@ru\": \"Russian\",\n",
      "          \"friend|close\": false,\n",
      "          \"friend|relative\": true\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Dave\",\n",
      "          \"friend|close\": true,\n",
      "          \"friend|relative\": true\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "helper.run_q(client, '''{\n",
    "  data(func: eq(name, \"Alice\")) {\n",
    "    name\n",
    "    car @facets\n",
    "    title\n",
    "    friend @facets {\n",
    "      name\n",
    "      car @facets\n",
    "      title@ru\n",
    "    }\n",
    "  }\n",
    "}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T05:54:51.766196Z",
     "start_time": "2019-06-01T05:54:47.714662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import sagas.graph.dgraph_helper as helper\n",
    "import pydgraph\n",
    "import json_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "client=helper.reset('''\n",
    "    name: string @index(exact, term) .\n",
    "    nsubj: string @index(exact, term) .\n",
    "    dobj: string @index(exact) .\n",
    "    pobj: string @index(exact) .\n",
    "    attr: string @index(exact) .\n",
    "    sents: string @index(fulltext) @lang .\n",
    "    lemmas: string @index(term) .\n",
    "    verbs: string @index(term) .\n",
    "''')\n",
    "\n",
    "def list_with_suffix(dir, suffix):\n",
    "    import os\n",
    "    rs=[]\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith(suffix):\n",
    "                rs.append(os.path.join(root, file))\n",
    "    return rs\n",
    "\n",
    "files=list_with_suffix('data/graph', '_feed.json')\n",
    "for file in tqdm(files):\n",
    "    feed_json=json_utils.read_json_file(file)\n",
    "    _=helper.set_json(client, feed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T06:03:33.113365Z",
     "start_time": "2019-06-01T06:03:33.080400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"sents@en:.\": \"Some people are afraid of spiders.\",\n",
      "      \"sents@de\": \"Manche Menschen haben Angst vor Spinnen.\",\n",
      "      \"nsubj|head\": \"are\",\n",
      "      \"nsubj|text\": \"Some people\",\n",
      "      \"nsubj\": \"people\",\n",
      "      \"verbs\": \"be\"\n",
      "    },\n",
      "    {\n",
      "      \"sents@en:.\": \"I'm not afraid to try.\",\n",
      "      \"sents@fr\": \"Je n'ai pas peur d'essayer.\",\n",
      "      \"nsubj|head\": \"'m\",\n",
      "      \"nsubj|text\": \"I\",\n",
      "      \"nsubj\": \"I\",\n",
      "      \"verbs\": \"be\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "vars = {'$a': 'afraid'}\n",
    "helper.query_with_vars(client, '''query data($a: string){\n",
    "  data(func: anyofterms(lemmas, $a)) {\n",
    "    sents@en:.\n",
    "    sents@fr\n",
    "    sents@de\n",
    "    sents@zh\n",
    "    sents@ja\n",
    "    sents@es\n",
    "    nsubj @facets\n",
    "    verbs    \n",
    "  }\n",
    "}''', vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:06:03.309417Z",
     "start_time": "2019-05-31T09:06:03.276891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 2D Array\n",
      "[[11 22 33]\n",
      " [44 55 66]\n",
      " [77 88 99]]\n",
      "Choose random row from 2D array\n",
      "pickup [2 0]\n",
      "[[77 88 99]\n",
      " [11 22 33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "array = numpy.array([[11 ,22, 33], [44, 55, 66], [77, 88, 99]]) \n",
    "print(\"Printing 2D Array\")\n",
    "print(array)\n",
    "print(\"Choose random row from 2D array\")\n",
    "randomRow = numpy.random.randint(3, size=2)\n",
    "print('pickup', randomRow)\n",
    "print(array[randomRow,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T01:45:51.749089Z",
     "start_time": "2019-06-01T01:45:49.839006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 167130\n",
      "pickup [144859 120344  68308  48399  66086  44530  12360 103419 108060  56722]\n",
      "[[\"It's not just illegal, it's also dangerous.\"\n",
      "  \"Ce n'est pas simplement illégal, c'est également dangereux.\\n\"]\n",
      " ['Termites are destroying the houses.'\n",
      "  'Les termites détruisent les maisons.\\n']\n",
      " ['The meeting was held here.' \"La réunion s'est tenue là.\\n\"]\n",
      " ['These are my suitcases.' 'Ce sont mes valises.\\n']\n",
      " ['I usually get up at eight.' 'Je me lève généralement à huit heures.\\n']\n",
      " ['Do you have a question?' 'Avez-vous une question\\u202f?\\n']\n",
      " ['Tom works there.' 'Tom y travaille.\\n']\n",
      " [\"I didn't think you'd be so late.\"\n",
      "  \"Je n'ai pas pensé que vous seriez tellement en retard.\\n\"]\n",
      " ['English is also studied in China.'\n",
      "  \"L'anglais est aussi étudié en Chine.\\n\"]\n",
      " ['All I think about is you.' \"Tout ce dont je pense, c'est toi.\\n\"]]\n"
     ]
    }
   ],
   "source": [
    "from sagas.nlu.corpus_helper import filter_term, lines, divide_chunks\n",
    "dataf = \"/pi/ai/seq2seq/fra-eng-2019/fra.txt\"\n",
    "pairs = lines(dataf)\n",
    "total=len(pairs)\n",
    "print('total', total)\n",
    "array = numpy.array(pairs)\n",
    "random_rows = numpy.random.randint(total, size=10)\n",
    "print('pickup', random_rows)\n",
    "print(array[random_rows,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T02:04:38.591677Z",
     "start_time": "2019-06-01T02:04:38.580462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not just illegal, it's also dangerous.\n",
      "\t Ce n'est pas simplement illégal, c'est également dangereux.\n",
      "Termites are destroying the houses.\n",
      "\t Les termites détruisent les maisons.\n",
      "The meeting was held here.\n",
      "\t La réunion s'est tenue là.\n",
      "These are my suitcases.\n",
      "\t Ce sont mes valises.\n",
      "I usually get up at eight.\n",
      "\t Je me lève généralement à huit heures.\n",
      "Do you have a question?\n",
      "\t Avez-vous une question ?\n",
      "Tom works there.\n",
      "\t Tom y travaille.\n",
      "I didn't think you'd be so late.\n",
      "\t Je n'ai pas pensé que vous seriez tellement en retard.\n",
      "English is also studied in China.\n",
      "\t L'anglais est aussi étudié en Chine.\n",
      "All I think about is you.\n",
      "\t Tout ce dont je pense, c'est toi.\n"
     ]
    }
   ],
   "source": [
    "rows=array[random_rows,:]\n",
    "for r in rows:\n",
    "    print(r[0])\n",
    "    print('\\t', r[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:11:57.711755Z",
     "start_time": "2019-05-31T09:11:53.755273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/pi/ai/corenlp/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/pi/ai/corenlp/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/pi/ai/corenlp/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/pi/ai/corenlp/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/pi/ai/corenlp/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/pi/ai/corenlp/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>look</td>\n",
       "      <td>looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buy</td>\n",
       "      <td>buying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>U.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>startup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma     word\n",
       "0     Apple    Apple\n",
       "1        be       is\n",
       "2      look  looking\n",
       "3        at       at\n",
       "4       buy   buying\n",
       "5      U.K.     U.K.\n",
       "6   startup  startup\n",
       "7       for      for\n",
       "8         $        $\n",
       "9         1        1\n",
       "10  billion  billion"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.corenlp_helper import langs, extract_lemma, extract_pos\n",
    "sents='Apple is looking at buying U.K. startup for $1 billion'\n",
    "nlp=langs['en']()\n",
    "doc = nlp(sents)\n",
    "extract_lemma(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T09:13:13.552410Z",
     "start_time": "2019-05-31T09:13:13.230847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Apple \tlemma: Apple\tupos: PROPN\txpos: NNP\n",
      "text: is \tlemma: be\tupos: AUX\txpos: VBZ\n",
      "text: looking \tlemma: look\tupos: VERB\txpos: VBG\n",
      "text: at \tlemma: at\tupos: SCONJ\txpos: IN\n",
      "text: buying \tlemma: buy\tupos: VERB\txpos: VBG\n",
      "text: U.K. \tlemma: U.K.\tupos: PROPN\txpos: NNP\n",
      "text: startup \tlemma: startup\tupos: NOUN\txpos: NN\n",
      "text: for \tlemma: for\tupos: ADP\txpos: IN\n",
      "text: $ \tlemma: $\tupos: SYM\txpos: $\n",
      "text: 1 \tlemma: 1\tupos: NUM\txpos: CD\n",
      "text: billion \tlemma: billion\tupos: NUM\txpos: CD\n",
      "('Apple', '3', 'nsubj')\n",
      "('is', '3', 'aux')\n",
      "('looking', '0', 'root')\n",
      "('at', '5', 'mark')\n",
      "('buying', '3', 'advcl')\n",
      "('U.K.', '7', 'compound')\n",
      "('startup', '5', 'obj')\n",
      "('for', '9', 'case')\n",
      "('$', '5', 'obl')\n",
      "('1', '9', 'compound')\n",
      "('billion', '9', 'nummod')\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: deps Pages: 1 -->\n",
       "<svg width=\"513pt\" height=\"325pt\"\n",
       " viewBox=\"0.00 0.00 512.56 324.92\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 320.9189)\">\n",
       "<title>deps</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-320.9189 508.5628,-320.9189 508.5628,4 -4,4\"/>\n",
       "<!-- Apple -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Apple</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"175.2693\" cy=\"-285.2\" rx=\"31.9393\" ry=\"31.9393\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.2693\" y=\"-281\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Apple</text>\n",
       "</g>\n",
       "<!-- is -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>is</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"175.2693\" cy=\"-217.2\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.2693\" y=\"-213\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">is</text>\n",
       "</g>\n",
       "<!-- looking -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>looking</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"37.1295\" cy=\"-198.2\" rx=\"37.2594\" ry=\"37.2594\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.1295\" y=\"-194\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">looking</text>\n",
       "</g>\n",
       "<!-- looking&#45;&gt;Apple -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>looking&#45;&gt;Apple</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M68.8216,-218.1596C89.9645,-231.4753 117.7942,-249.0024 139.6954,-262.7956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"138.0503,-265.8959 148.3772,-268.2634 141.7807,-259.9727 138.0503,-265.8959\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.4279\" y=\"-252\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- looking&#45;&gt;is -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>looking&#45;&gt;is</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M74.1484,-203.2917C97.1202,-206.4512 126.1697,-210.4468 147.2327,-213.3438\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"146.7731,-216.8135 157.1567,-214.7088 147.7269,-209.8787 146.7731,-216.8135\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.4279\" y=\"-212\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">aux</text>\n",
       "</g>\n",
       "<!-- buying -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>buying</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"175.2693\" cy=\"-146.2\" rx=\"34.8458\" ry=\"34.8458\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.2693\" y=\"-142\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">buying</text>\n",
       "</g>\n",
       "<!-- looking&#45;&gt;buying -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>looking&#45;&gt;buying</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M71.988,-185.0782C90.5861,-178.0773 113.6115,-169.4099 133.1989,-162.0366\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.6686,-165.2232 142.7944,-158.4246 132.2024,-158.672 134.6686,-165.2232\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.4279\" y=\"-179\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- at -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>at</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.8833\" cy=\"-243.2\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.8833\" y=\"-239\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">at</text>\n",
       "</g>\n",
       "<!-- buying&#45;&gt;at -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>buying&#45;&gt;at</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M203.6054,-166.7712C228.0864,-184.5437 263.0223,-209.9062 285.824,-226.4596\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.0615,-229.5051 294.2101,-232.5477 288.1739,-223.8404 284.0615,-229.5051\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.3246\" y=\"-206\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- startup -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>startup</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.8833\" cy=\"-173.2\" rx=\"34.3527\" ry=\"34.3527\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.8833\" y=\"-169\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">startup</text>\n",
       "</g>\n",
       "<!-- buying&#45;&gt;startup -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>buying&#45;&gt;startup</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M209.3315,-153.0831C226.4235,-156.537 247.3145,-160.7585 265.5376,-164.4409\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.8509,-167.8728 275.3461,-166.423 266.2375,-161.0115 264.8509,-167.8728\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.3246\" y=\"-164\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">obj</text>\n",
       "</g>\n",
       "<!-- $ -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>$</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.8833\" cy=\"-103.2\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.8833\" y=\"-99\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">$</text>\n",
       "</g>\n",
       "<!-- buying&#45;&gt;$ -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>buying&#45;&gt;$</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M208.2975,-135.5708C231.0104,-128.2613 260.792,-118.6769 282.0426,-111.838\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.2742,-115.1185 291.7211,-108.7232 281.1297,-108.455 283.2742,-115.1185\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.3246\" y=\"-131\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">obl</text>\n",
       "</g>\n",
       "<!-- U.K. -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>U.K.</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"471.3628\" cy=\"-224.2\" rx=\"27.1044\" ry=\"27.1044\"/>\n",
       "<text text-anchor=\"middle\" x=\"471.3628\" y=\"-220\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">U.K.</text>\n",
       "</g>\n",
       "<!-- startup&#45;&gt;U.K. -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>startup&#45;&gt;U.K.</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M341.7635,-183.5206C368.9344,-192.0492 407.4524,-204.1394 435.4306,-212.9214\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"434.6318,-216.339 445.221,-215.9945 436.7282,-209.6603 434.6318,-216.339\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.611\" y=\"-210\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- for -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>for</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"471.3628\" cy=\"-158.2\" rx=\"20.3372\" ry=\"20.3372\"/>\n",
       "<text text-anchor=\"middle\" x=\"471.3628\" y=\"-154\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">for</text>\n",
       "</g>\n",
       "<!-- $&#45;&gt;for -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>$&#45;&gt;for</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M325.9644,-108.982C353.5798,-118.33 408.3507,-136.8701 442.222,-148.3357\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"441.4153,-151.7577 452.0096,-151.6489 443.6598,-145.1273 441.4153,-151.7577\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.611\" y=\"-143\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"471.3628\" cy=\"-102.2\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"471.3628\" y=\"-98\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- $&#45;&gt;1 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>$&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M326.8923,-103.0892C355.0742,-102.9157 409.8235,-102.5788 443.2356,-102.3731\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"443.2949,-105.8729 453.2732,-102.3113 443.2518,-98.8731 443.2949,-105.8729\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.611\" y=\"-105\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- billion -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>billion</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"471.3628\" cy=\"-33.2\" rx=\"33.4012\" ry=\"33.4012\"/>\n",
       "<text text-anchor=\"middle\" x=\"471.3628\" y=\"-29\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">billion</text>\n",
       "</g>\n",
       "<!-- $&#45;&gt;billion -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>$&#45;&gt;billion</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M325.6595,-95.9724C350.4131,-85.308 397.4517,-65.0426 431.3977,-50.4179\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"432.7966,-53.6263 440.5957,-46.4552 430.0269,-47.1975 432.7966,-53.6263\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.611\" y=\"-84\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nummod</text>\n",
       "</g>\n",
       "<!-- billion&#45;&gt;looking -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>billion&#45;&gt;looking</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M437.873,-34.1501C375.75,-37.1739 239.9509,-49.7785 140.5969,-102.2 112.7317,-116.9023 86.7573,-141.0522 67.8033,-161.451\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.0265,-159.3025 60.8934,-169.0579 70.208,-164.0092 65.0265,-159.3025\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.3246\" y=\"-70\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x10f04a438>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.corenlp_helper import CoreNlpViz, nlp_en, nlp_fr\n",
    "viz=CoreNlpViz()\n",
    "viz.analyse(sents, nlp)\n",
    "viz.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T23:37:56.521133Z",
     "start_time": "2019-05-31T23:37:55.818614Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "doc = nlp_spacy(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T01:40:59.790383Z",
     "start_time": "2019-06-01T01:40:59.738871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n",
      "[\n",
      "  {\n",
      "    \"ORG\": \"Apple\",\n",
      "    \"ORG|loc\": \"0 5\",\n",
      "    \"GPE\": \"U.K.\",\n",
      "    \"GPE|loc\": \"27 31\",\n",
      "    \"MONEY\": \"$1 billion\",\n",
      "    \"MONEY|loc\": \"44 54\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def put_entities(doc, props):\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        props[ent.label_]=ent.text\n",
    "        facet=\"%s|%s\"%(ent.label_, 'loc')\n",
    "        props[facet]=\"%d %d\"%(ent.start_char, ent.end_char)\n",
    "\n",
    "sentences=[\"Apple is looking at buying U.K. startup for $1 billion\"]\n",
    "dataset=[]\n",
    "for sents in sentences:\n",
    "    props={}\n",
    "    doc = nlp_spacy(sents)\n",
    "    put_entities(doc, props)\n",
    "    dataset.append(props)\n",
    "print(json.dumps(dataset, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:30:36.744000Z",
     "start_time": "2019-05-31T22:30:36.718880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "PERSON\n",
      "Best\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_spacy(u\"Mr. Best flew to New York on Saturday morning.\")\n",
    "ents = list(doc.ents)\n",
    "print(ents[0].label)\n",
    "print(ents[0].label_)\n",
    "print(ents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T00:13:27.675145Z",
     "start_time": "2019-06-01T00:13:27.628554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple be look at buy u.k. startup for $ 1 billion\n"
     ]
    }
   ],
   "source": [
    "def doc_collect(doc):\n",
    "    toks={'text':[], 'lemma':[], 'pos':[], 'tag':[], 'dep':[]}\n",
    "    for token in doc:\n",
    "        # print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #        token.shape_, token.is_alpha, token.is_stop)\n",
    "        toks['text'].append(token.text)\n",
    "        toks['lemma'].append(token.lemma_)\n",
    "        toks['pos'].append(token.pos_)\n",
    "        toks['tag'].append(token.tag_)\n",
    "        toks['dep'].append(token.dep_)\n",
    "    return toks\n",
    "\n",
    "doc = nlp_spacy(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "toks=doc_collect(doc)\n",
    "lemmas=' '.join(toks['lemma'])\n",
    "print(lemmas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
