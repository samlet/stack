{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T08:17:28.951373Z",
     "start_time": "2019-02-10T08:17:28.940489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"hello\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simple_pb2 import MyObj, Foo\n",
    "obj=MyObj(name='hello')\n",
    "print(obj)\n",
    "\n",
    "message = Foo()\n",
    "message.name = \"Bender\"\n",
    "assert message.HasField(\"name\")\n",
    "message.serial_number = 2716057\n",
    "assert message.HasField(\"serial_number\")\n",
    "assert not message.HasField(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T08:22:56.078678Z",
     "start_time": "2019-02-10T08:22:56.068963Z"
    }
   },
   "outputs": [],
   "source": [
    "message.ClearField(\"test_oneof\")\n",
    "\n",
    "assert message.WhichOneof(\"test_oneof\") is None\n",
    "message.name = \"Bender\"\n",
    "assert message.WhichOneof(\"test_oneof\") == \"name\"\n",
    "\n",
    "# HasField and ClearField also accept oneof names in addition \n",
    "# to field names:\n",
    "\n",
    "# assert not message.HasField(\"test_oneof\")\n",
    "message.name = \"Bender\"\n",
    "# assert message.HasField(\"test_oneof\")\n",
    "message.serial_number = 2716057\n",
    "# assert message.HasField(\"test_oneof\")\n",
    "message.ClearField(\"test_oneof\")\n",
    "assert not message.HasField(\"test_oneof\")\n",
    "assert not message.HasField(\"serial_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T16:32:29.009831Z",
     "start_time": "2018-12-15T16:32:29.000594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"you\"\n",
      "\n",
      "text: \"\\345\\276\\220\\345\\205\\210\\347\\224\\237\\350\\277\\230\\345\\205\\267\\344\\275\\223\\345\\270\\256\\345\\212\\251\\344\\273\\226\\347\\241\\256\\345\\256\\232\\344\\272\\206\\346\\212\\212\\347\\224\\273\\351\\233\\204\\351\\271\\260\\343\\200\\201\\346\\235\\276\\351\\274\\240\\345\\222\\214\\351\\272\\273\\351\\233\\200\\344\\275\\234\\344\\270\\272\\344\\270\\273\\346\\224\\273\\347\\233\\256\\346\\240\\207\\343\\200\\202\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from protocol.nlpserv_pb2 import PingRequest, NlParseRequest\n",
    "ping=PingRequest(name='you')\n",
    "print(ping)\n",
    "req=NlParseRequest(text=\"徐先生还具体帮助他确定了把画雄鹰、松鼠和麻雀作为主攻目标。\")\n",
    "print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-25T08:02:02.868094Z",
     "start_time": "2019-08-25T08:02:02.759040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 徐先生 主谓关系 4 帮助\n",
      "2 还 状中结构 4 帮助\n",
      "3 具体 状中结构 4 帮助\n",
      "4 帮助 核心关系 0 _core_\n",
      "5 他 兼语 4 帮助\n",
      "6 确定 动宾关系 4 帮助\n",
      "7 了 右附加关系 6 确定\n",
      "8 把 状中结构 15 作为\n",
      "9 画 介宾关系 8 把\n",
      "10 雄鹰 动宾关系 9 画\n",
      "11 、 标点符号 12 松鼠\n",
      "12 松鼠 并列关系 10 雄鹰\n",
      "13 和 左附加关系 14 麻雀\n",
      "14 麻雀 并列关系 10 雄鹰\n",
      "15 作为 动宾关系 6 确定\n",
      "16 主攻 定中关系 17 目标\n",
      "17 目标 动宾关系 15 作为\n",
      "18 。 标点符号 4 帮助\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "import time\n",
    "\n",
    "import grpc\n",
    "import nlpserv_pb2\n",
    "import nlpserv_pb2_grpc\n",
    "\n",
    "def nlp_procs(p, func):\n",
    "    # NOTE(gRPC Python Team): .close() is possible on a channel and should be\n",
    "    # used in circumstances in which the with statement does not fit the needs\n",
    "    # of the code.\n",
    "    # with grpc.insecure_channel('localhost:10052') as channel:\n",
    "    with grpc.insecure_channel(\n",
    "            target='localhost:10052',\n",
    "            options=[('grpc.lb_policy_name', 'pick_first'),\n",
    "                     ('grpc.enable_retries', 0), ('grpc.keepalive_timeout_ms',\n",
    "                                                  10000)]) as channel:\n",
    "        stub = nlpserv_pb2_grpc.NlpProcsStub(channel)\n",
    "        response = func(stub, p)\n",
    "    # print(\"Greeter client received: \" + response.message)\n",
    "    return response\n",
    "\n",
    "def get_head_lemma(tree, id):\n",
    "    if id==0:\n",
    "        return \"_core_\"\n",
    "    for word in result.words:\n",
    "        if word.id==id:\n",
    "            return word.lemma\n",
    "\n",
    "text=\"徐先生还具体帮助他确定了把画雄鹰、松鼠和麻雀作为主攻目标。\"\n",
    "result=nlp_procs(text, lambda stub, s: stub.ParseDependency(nlpserv_pb2.NlParseRequest(text=s)))   \n",
    "for word in result.words:\n",
    "    print(word.id, word.lemma, word.deprel, word.head_id, \\\n",
    "          get_head_lemma(result, word.head_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T07:12:25.517112Z",
     "start_time": "2018-12-16T07:12:25.508030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "add = lambda x, y: x + y\n",
    "print(add(3, 5))\n",
    "\n",
    "def invoker(func):\n",
    "   return func(3, 6)\n",
    "result=invoker(lambda x, y: x + y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T09:29:50.126523Z",
     "start_time": "2018-12-16T09:29:49.954162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xú xiān shēng huán jù tǐ bāng zhù tā què dìng le bǎ huà xióng yīng none sōng shǔ hé má què zuò wéi zhǔ gōng mù biāo none \n"
     ]
    }
   ],
   "source": [
    "result=nlp_procs(text, lambda stub, s: stub.GetPinyin(nlpserv_pb2.NlPinyinRequest(text=s, presentation=1)))   \n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T13:12:00.177311Z",
     "start_time": "2018-12-26T13:12:00.140779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=[\n",
    "    \"山东苹果丰收\",\n",
    "    \"农民在江苏种水稻\",\n",
    "    \"奥运会女排夺冠\",\n",
    "    \"世界锦标赛胜出\",\n",
    "    \"中国足球失败\"\n",
    "]\n",
    "p=nlpserv_pb2.NlDocumentSet(textList=docs)\n",
    "nlp_procs(p, lambda stub, p: stub.AddDocuments(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T13:12:04.516153Z",
     "start_time": "2018-12-26T13:12:04.493544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国足球失败 0.3437924385070801\n",
      "奥运会女排夺冠 0.2620129883289337\n",
      "世界锦标赛胜出 0.18041817843914032\n",
      "农民在江苏种水稻 0.1255408078432083\n",
      "山东苹果丰收 0.08718200027942657\n"
     ]
    }
   ],
   "source": [
    "p=nlpserv_pb2.NlText(text=\"体育\")\n",
    "result=nlp_procs(p, lambda stub, p: stub.GetNearestDocuments(p))\n",
    "for doc in result.docs:\n",
    "    print(doc.content, doc.similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T13:14:36.866089Z",
     "start_time": "2018-12-26T13:14:36.847565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这里\n",
      "是\n",
      "北京\n"
     ]
    }
   ],
   "source": [
    "import nlpserv_pb2 as nlp_messages\n",
    "import nlpserv_pb2_grpc as nlp_service\n",
    "p = nlp_messages.NlTokenizerRequest(text=nlp_messages.NlText(text=\"这里是北京\"))\n",
    "# response = client.Tokenizer(request)\n",
    "result=nlp_procs(p, lambda stub, p: stub.Tokenizer(p))\n",
    "for resp in result.tokens:\n",
    "    print(resp.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
