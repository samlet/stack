{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ⊕ [PhraseMatcher · spaCy API Documentation](https://spacy.io/api/phrasematcher)\n",
    "* ⊕ [Rule-based matching · spaCy Usage Documentation](https://spacy.io/usage/rule-based-matching#matcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T07:13:49.979882Z",
     "start_time": "2019-09-17T07:13:48.455677Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I live in NewYork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T07:13:52.707205Z",
     "start_time": "2019-09-17T07:13:52.682598Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "ruler = EntityRuler(nlp)\n",
    "ruler.add_patterns([{\"label\": \"ORG\", \"pattern\": \"Apple\"}])\n",
    "nlp.add_pipe(ruler, before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T17:44:31.270212Z",
     "start_time": "2019-08-23T17:44:31.264929Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/v2-1\n",
    "# Matches \"love cats\" or \"likes flowers\"\n",
    "pattern1 = [{\"LEMMA\": {\"IN\": [\"like\", \"love\"]}}, {\"POS\": \"NOUN\"}]\n",
    "# Matches tokens of length >= 10\n",
    "pattern2 = [{\"LENGTH\": {\">=\": 10}}]\n",
    "# Matches custom attribute with regex\n",
    "pattern3 = [{\"_\": {\"country\": {\"REGEX\": \"^([Uu](\\.?|nited) ?[Ss](\\.?|tates)\"}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T17:44:41.969125Z",
     "start_time": "2019-08-23T17:44:41.827705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11920309760829426267, 0, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"POS\")\n",
    "matcher.add(\"PATTERN\", None, nlp(u\"I love cats\"))\n",
    "doc = nlp(u\"You like dogs\")\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T17:48:42.051445Z",
     "start_time": "2019-08-23T17:48:42.025058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "\n",
    "doc = nlp(u\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:18:44.574559Z",
     "start_time": "2019-08-31T14:18:42.647098Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "city_getter = lambda doc: any(city in doc.text for city in ('New York', 'Paris', 'Berlin'))\n",
    "Doc.set_extension('has_city', getter=city_getter)\n",
    "doc = nlp(u'I like New York')\n",
    "assert doc._.has_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-31T14:21:33.171177Z",
     "start_time": "2019-08-31T14:21:32.820626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaofeiwu/miniconda3/envs/rasa_1x/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/xiaofeiwu/miniconda3/envs/rasa_1x/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "apples = nlp(u\"I like apples\")\n",
    "oranges = nlp(u\"I like oranges\")\n",
    "apples_oranges = apples.similarity(oranges)\n",
    "oranges_apples = oranges.similarity(apples)\n",
    "assert apples_oranges == oranges_apples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
