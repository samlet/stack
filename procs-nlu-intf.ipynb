{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:49:07.007889Z",
     "start_time": "2019-08-17T08:49:06.860042Z"
    }
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "class WordIntf(abc.ABC):\n",
    "    def __init__(self, data):\n",
    "        self.ctx=self.setup(data)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def setup(self, data):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def dependency_relation(self):\n",
    "        return self.ctx['dependency_relation']    \n",
    "    @property\n",
    "    def lemma(self):\n",
    "        \"\"\" Access lemma of this word. \"\"\"\n",
    "        return self.ctx['lemma']\n",
    "\n",
    "    @property\n",
    "    def governor(self):\n",
    "        \"\"\" Access governor of this word. \"\"\"\n",
    "        return self.ctx['governor']\n",
    "\n",
    "    @property\n",
    "    def pos(self):\n",
    "        \"\"\" Access (treebank-specific) part-of-speech of this word. Example: 'NNP'\"\"\"\n",
    "        return self.ctx['pos']\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        \"\"\" Access text of this word. Example: 'The'\"\"\"\n",
    "        return self.ctx['text']\n",
    "\n",
    "    @property\n",
    "    def xpos(self):\n",
    "        \"\"\" Access treebank-specific part-of-speech of this word. Example: 'NNP'\"\"\"\n",
    "        return self.ctx['xpos']\n",
    "\n",
    "    @property\n",
    "    def upos(self):\n",
    "        \"\"\" Access universal part-of-speech of this word. Example: 'DET'\"\"\"\n",
    "        return self.ctx['upos']\n",
    "\n",
    "    @property\n",
    "    def feats(self):\n",
    "        \"\"\" Access morphological features of this word. Example: 'Gender=Fem'\"\"\"\n",
    "        return self.ctx['feats']\n",
    "\n",
    "    @property\n",
    "    def index(self):\n",
    "        \"\"\" Access index of this word. \"\"\"\n",
    "        return self.ctx['index']\n",
    "    \n",
    "    def __repr__(self):\n",
    "        features = ['index', 'text', 'lemma', 'upos', 'xpos', 'feats', 'governor', 'dependency_relation']\n",
    "        feature_str = \";\".join([\"{}={}\".format(k, getattr(self, k)) for k in features if getattr(self, k) is not None])\n",
    "\n",
    "        return f\"<{self.__class__.__name__} {feature_str}>\"\n",
    "    \n",
    "class SentenceIntf(abc.ABC):\n",
    "    def __init__(self, sent):\n",
    "        self._words, self._dependencies=self.setup(sent)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def setup(self, sent):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def dependencies(self):\n",
    "        \"\"\" Access list of dependencies for this sentence. \"\"\"\n",
    "        return self._dependencies\n",
    "\n",
    "    @property\n",
    "    def words(self):\n",
    "        \"\"\" Access list of words for this sentence. \"\"\"\n",
    "        return self._words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:49:27.563525Z",
     "start_time": "2019-08-17T08:49:27.537395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ok True\n",
      "[<WordImpl index=1;text=ok;lemma=ok;upos=VERB;xpos=v;feats=['ff'];governor=0;dependency_relation=nsubj>]\n",
      "[(2, 'rel', <WordImpl index=1;text=ok;lemma=ok;upos=VERB;xpos=v;feats=['ff'];governor=0;dependency_relation=nsubj>)]\n"
     ]
    }
   ],
   "source": [
    "class WordImpl(WordIntf):\n",
    "    def setup(self, data):\n",
    "        features = ['index', 'text', 'lemma', 'upos', 'xpos', 'feats', 'governor', 'dependency_relation']\n",
    "        stuffs=[1, 'ok', 'ok', 'VERB', 'v', ['ff'], 0, 'nsubj']\n",
    "        return dict(zip(features, stuffs))\n",
    "\n",
    "class SentImpl(SentenceIntf):\n",
    "    def setup(self, words):\n",
    "        governor, dependency_relation, word=(2,'rel',words[0])\n",
    "        dependencies=[]\n",
    "        dependencies.append((governor, dependency_relation, word))\n",
    "        return words, dependencies\n",
    "    \n",
    "data={}\n",
    "wi=WordImpl(data)\n",
    "print(wi.index, wi.text, isinstance(wi, WordIntf))\n",
    "si=SentImpl([wi])\n",
    "print(si.words)\n",
    "print(si.dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T05:01:02.233666Z",
     "start_time": "2019-08-17T05:01:02.225989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WordImpl index=1;text=ok;lemma=ok;upos=VERB;xpos=v;feats=['ff'];governor=0;dependency_relation=nsubj>] ** [(2, 'rel', <WordImpl index=1;text=ok;lemma=ok;upos=VERB;xpos=v;feats=['ff'];governor=0;dependency_relation=nsubj>)]\n"
     ]
    }
   ],
   "source": [
    "class ParserImpl(object):\n",
    "    def __call__(self, sents):\n",
    "        return SentImpl(sents)\n",
    "\n",
    "par=ParserImpl()\n",
    "s=par([wi])\n",
    "print(s.words, '**', s.dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T08:57:36.873169Z",
     "start_time": "2019-08-17T08:57:36.764257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "from sagas.nlu.corenlp_helper import get_nlp\n",
    "def test_parser(lang, sents):\n",
    "    nlp=get_nlp(lang)\n",
    "    doc = nlp(sents)\n",
    "    print(len(doc.sentences[0].words))\n",
    "    print([word.index for word in doc.sentences[0].words])\n",
    "test_parser('en', 'it is a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T09:09:36.952949Z",
     "start_time": "2019-08-17T09:09:36.824646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "class CoreNlpWordImpl(WordIntf):\n",
    "    def setup(self, data):\n",
    "        features = ['index', 'text', 'lemma', 'upos', 'xpos', 'feats', 'governor', 'dependency_relation']\n",
    "        attrs={k:getattr(data, k) for k in features if getattr(data, k) is not None}\n",
    "        return attrs\n",
    "    \n",
    "class CoreNlpSentImpl(SentenceIntf):\n",
    "    def setup(self, sent):\n",
    "        words=[]\n",
    "        for word in sent.words:\n",
    "            words.append(CoreNlpWordImpl(word))\n",
    "        deps=[]\n",
    "        for dep in sent.dependencies: \n",
    "            # (governor, word.dependency_relation, word)            \n",
    "            deps.append((CoreNlpWordImpl(dep[0]), dep[1], CoreNlpWordImpl(dep[2])))\n",
    "        return words, deps\n",
    "class CoreNlpParserImpl(object):\n",
    "    def __init__(self, lang):\n",
    "        self.lang=lang\n",
    "    def __call__(self, sents):\n",
    "        nlp=get_nlp(self.lang)\n",
    "        doc = nlp(sents)\n",
    "        return CoreNlpSentImpl(doc.sentences[0])\n",
    "    \n",
    "parser=CoreNlpParserImpl('en')\n",
    "doc=parser('it is a cat')\n",
    "print(len(doc.words))\n",
    "print([word.index for word in doc.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T09:14:04.458348Z",
     "start_time": "2019-08-17T09:14:04.450404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aux': 'is',\n",
       "  'delegator': False,\n",
       "  'domains': [('nsubj', '1', 'it', 'it', ['it'], ['c_pron', 'x_prp']),\n",
       "   ('cop', '2', 'is', 'be', ['is'], ['c_aux', 'x_vbz']),\n",
       "   ('det', '3', 'a', 'a', ['a'], ['c_det', 'x_dt'])],\n",
       "  'governor': 4,\n",
       "  'head': 'cat',\n",
       "  'head_pos': 'noun',\n",
       "  'index': '2',\n",
       "  'lemma': 'be',\n",
       "  'rel': 'cop',\n",
       "  'stems': [('nsubj', ['it']), ('cop', ['be']), ('det', ['a'])],\n",
       "  'type': 'aux_domains'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.corenlp_parser import get_chunks\n",
    "get_chunks(doc)\n",
    "# r= get_chunks(doc)\n",
    "# data_y = json.dumps(r, indent=2, ensure_ascii=False)\n",
    "# print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T09:19:32.586554Z",
     "start_time": "2019-08-17T09:19:32.563518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aux_domains(be)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>children</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>[it]</td>\n",
       "      <td>[c_pron, x_prp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cop</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>[is]</td>\n",
       "      <td>[c_aux, x_vbz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>det</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[c_det, x_dt]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rel index text lemma children         features\n",
       "0  nsubj     1   it    it     [it]  [c_pron, x_prp]\n",
       "1    cop     2   is    be     [is]   [c_aux, x_vbz]\n",
       "2    det     3    a     a      [a]    [c_det, x_dt]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sagas\n",
    "from sagas.tool.misc import print_stem_chunks\n",
    "rs=get_chunks(doc)\n",
    "for r in rs:\n",
    "    df = sagas.to_df(r['domains'], ['rel', 'index', 'text', 'lemma', 'children', 'features'])\n",
    "    print('%s(%s)'%(r['type'], r['lemma']))\n",
    "    display(df)\n",
    "    print_stem_chunks(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
