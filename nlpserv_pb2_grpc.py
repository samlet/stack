# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
import grpc

import common_types_pb2 as common__types__pb2
import nlpserv_pb2 as nlpserv__pb2


class NlpProcsStub(object):
  """The service definition.
  """

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Ping = channel.unary_unary(
        '/nlpserv.NlpProcs/Ping',
        request_serializer=common__types__pb2.PingRequest.SerializeToString,
        response_deserializer=common__types__pb2.PingReply.FromString,
        )
    self.ParseDependency = channel.unary_unary(
        '/nlpserv.NlpProcs/ParseDependency',
        request_serializer=nlpserv__pb2.NlParseRequest.SerializeToString,
        response_deserializer=nlpserv__pb2.NlSentence.FromString,
        )
    self.GetPinyin = channel.unary_unary(
        '/nlpserv.NlpProcs/GetPinyin',
        request_serializer=nlpserv__pb2.NlPinyinRequest.SerializeToString,
        response_deserializer=nlpserv__pb2.NlText.FromString,
        )
    self.AddDocuments = channel.unary_unary(
        '/nlpserv.NlpProcs/AddDocuments',
        request_serializer=nlpserv__pb2.NlDocumentSet.SerializeToString,
        response_deserializer=nlpserv__pb2.NlResult.FromString,
        )
    self.GetNearestDocuments = channel.unary_unary(
        '/nlpserv.NlpProcs/GetNearestDocuments',
        request_serializer=nlpserv__pb2.NlText.SerializeToString,
        response_deserializer=nlpserv__pb2.NlDocumentSimilaritySet.FromString,
        )
    self.Tokenizer = channel.unary_unary(
        '/nlpserv.NlpProcs/Tokenizer',
        request_serializer=nlpserv__pb2.NlTokenizerRequest.SerializeToString,
        response_deserializer=nlpserv__pb2.NlTokens.FromString,
        )
    self.EntityExtractor = channel.unary_unary(
        '/nlpserv.NlpProcs/EntityExtractor',
        request_serializer=nlpserv__pb2.NlTokenizerRequest.SerializeToString,
        response_deserializer=nlpserv__pb2.NlEntities.FromString,
        )
    self.ParseAmountTerms = channel.unary_unary(
        '/nlpserv.NlpProcs/ParseAmountTerms',
        request_serializer=nlpserv__pb2.NlText.SerializeToString,
        response_deserializer=nlpserv__pb2.NlAmountList.FromString,
        )
    self.GetDependencyGraph = channel.unary_unary(
        '/nlpserv.NlpProcs/GetDependencyGraph',
        request_serializer=nlpserv__pb2.NlTexts.SerializeToString,
        response_deserializer=nlpserv__pb2.NlDepWords.FromString,
        )


class NlpProcsServicer(object):
  """The service definition.
  """

  def Ping(self, request, context):
    """Sends a greeting
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def ParseDependency(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def GetPinyin(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def AddDocuments(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def GetNearestDocuments(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def Tokenizer(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def EntityExtractor(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def ParseAmountTerms(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')

  def GetDependencyGraph(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_NlpProcsServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Ping': grpc.unary_unary_rpc_method_handler(
          servicer.Ping,
          request_deserializer=common__types__pb2.PingRequest.FromString,
          response_serializer=common__types__pb2.PingReply.SerializeToString,
      ),
      'ParseDependency': grpc.unary_unary_rpc_method_handler(
          servicer.ParseDependency,
          request_deserializer=nlpserv__pb2.NlParseRequest.FromString,
          response_serializer=nlpserv__pb2.NlSentence.SerializeToString,
      ),
      'GetPinyin': grpc.unary_unary_rpc_method_handler(
          servicer.GetPinyin,
          request_deserializer=nlpserv__pb2.NlPinyinRequest.FromString,
          response_serializer=nlpserv__pb2.NlText.SerializeToString,
      ),
      'AddDocuments': grpc.unary_unary_rpc_method_handler(
          servicer.AddDocuments,
          request_deserializer=nlpserv__pb2.NlDocumentSet.FromString,
          response_serializer=nlpserv__pb2.NlResult.SerializeToString,
      ),
      'GetNearestDocuments': grpc.unary_unary_rpc_method_handler(
          servicer.GetNearestDocuments,
          request_deserializer=nlpserv__pb2.NlText.FromString,
          response_serializer=nlpserv__pb2.NlDocumentSimilaritySet.SerializeToString,
      ),
      'Tokenizer': grpc.unary_unary_rpc_method_handler(
          servicer.Tokenizer,
          request_deserializer=nlpserv__pb2.NlTokenizerRequest.FromString,
          response_serializer=nlpserv__pb2.NlTokens.SerializeToString,
      ),
      'EntityExtractor': grpc.unary_unary_rpc_method_handler(
          servicer.EntityExtractor,
          request_deserializer=nlpserv__pb2.NlTokenizerRequest.FromString,
          response_serializer=nlpserv__pb2.NlEntities.SerializeToString,
      ),
      'ParseAmountTerms': grpc.unary_unary_rpc_method_handler(
          servicer.ParseAmountTerms,
          request_deserializer=nlpserv__pb2.NlText.FromString,
          response_serializer=nlpserv__pb2.NlAmountList.SerializeToString,
      ),
      'GetDependencyGraph': grpc.unary_unary_rpc_method_handler(
          servicer.GetDependencyGraph,
          request_deserializer=nlpserv__pb2.NlTexts.FromString,
          response_serializer=nlpserv__pb2.NlDepWords.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'nlpserv.NlpProcs', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))


class CabochaNlpProcsStub(object):
  # missing associated documentation comment in .proto file
  pass

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Tokenizer = channel.unary_unary(
        '/nlpserv.CabochaNlpProcs/Tokenizer',
        request_serializer=nlpserv__pb2.NlText.SerializeToString,
        response_deserializer=nlpserv__pb2.NlCabochaChunks.FromString,
        )


class CabochaNlpProcsServicer(object):
  # missing associated documentation comment in .proto file
  pass

  def Tokenizer(self, request, context):
    # missing associated documentation comment in .proto file
    pass
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_CabochaNlpProcsServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Tokenizer': grpc.unary_unary_rpc_method_handler(
          servicer.Tokenizer,
          request_deserializer=nlpserv__pb2.NlText.FromString,
          response_serializer=nlpserv__pb2.NlCabochaChunks.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'nlpserv.CabochaNlpProcs', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))
