{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T03:59:58.805739Z",
     "start_time": "2019-05-28T03:59:58.795039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting up Java Stanford CoreNLP Server...\n"
     ]
    }
   ],
   "source": [
    "from stanfordnlp.server import CoreNLPClient\n",
    "import os\n",
    "\n",
    "text = \"Chris Manning is a nice person. Chris wrote a simple sentence. He also gives oranges to people.\"\n",
    "print('starting up Java Stanford CoreNLP Server...')\n",
    "\n",
    "os.environ[\"CORENLP_HOME\"] = '/pi/stanford-corenlp-full-2018-10-05'\n",
    "client=CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner','parse','depparse','coref'], timeout=60000, memory='16G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:02:53.826059Z",
     "start_time": "2019-05-28T04:01:16.499579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx16G -cp /pi/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-17432efeeaa445d2.props -preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\n",
      "---\n",
      "constituency parse of first sentence\n",
      "child {\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"Chris\"\n",
      "      }\n",
      "      value: \"NNP\"\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        value: \"Manning\"\n",
      "      }\n",
      "      value: \"NNP\"\n",
      "    }\n",
      "    value: \"NP\"\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"is\"\n",
      "      }\n",
      "      value: \"VBZ\"\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        child {\n",
      "          value: \"a\"\n",
      "        }\n",
      "        value: \"DT\"\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          value: \"nice\"\n",
      "        }\n",
      "        value: \"JJ\"\n",
      "      }\n",
      "      child {\n",
      "        child {\n",
      "          value: \"person\"\n",
      "        }\n",
      "        value: \"NN\"\n",
      "      }\n",
      "      value: \"NP\"\n",
      "    }\n",
      "    value: \"VP\"\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      value: \".\"\n",
      "    }\n",
      "    value: \".\"\n",
      "  }\n",
      "  value: \"S\"\n",
      "}\n",
      "value: \"ROOT\"\n",
      "score: 5864.000343322754\n",
      "\n",
      "---\n",
      "first subtree of constituency parse\n",
      "child {\n",
      "  child {\n",
      "    child {\n",
      "      value: \"Chris\"\n",
      "    }\n",
      "    value: \"NNP\"\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      value: \"Manning\"\n",
      "    }\n",
      "    value: \"NNP\"\n",
      "  }\n",
      "  value: \"NP\"\n",
      "}\n",
      "child {\n",
      "  child {\n",
      "    child {\n",
      "      value: \"is\"\n",
      "    }\n",
      "    value: \"VBZ\"\n",
      "  }\n",
      "  child {\n",
      "    child {\n",
      "      child {\n",
      "        value: \"a\"\n",
      "      }\n",
      "      value: \"DT\"\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        value: \"nice\"\n",
      "      }\n",
      "      value: \"JJ\"\n",
      "    }\n",
      "    child {\n",
      "      child {\n",
      "        value: \"person\"\n",
      "      }\n",
      "      value: \"NN\"\n",
      "    }\n",
      "    value: \"NP\"\n",
      "  }\n",
      "  value: \"VP\"\n",
      "}\n",
      "child {\n",
      "  child {\n",
      "    value: \".\"\n",
      "  }\n",
      "  value: \".\"\n",
      "}\n",
      "value: \"S\"\n",
      "\n",
      "---\n",
      "value of first subtree of constituency parse\n",
      "S\n",
      "---\n",
      "dependency parse of first sentence\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 1\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 2\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 3\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 4\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 5\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 6\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 7\n",
      "}\n",
      "edge {\n",
      "  source: 2\n",
      "  target: 1\n",
      "  dep: \"compound\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 2\n",
      "  dep: \"nsubj\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 3\n",
      "  dep: \"cop\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 4\n",
      "  dep: \"det\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 5\n",
      "  dep: \"amod\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 6\n",
      "  target: 7\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "root: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# submit the request to the server\n",
    "ann = client.annotate(text)\n",
    "\n",
    "# get the first sentence\n",
    "sentence = ann.sentence[0]\n",
    "\n",
    "# get the constituency parse of the first sentence\n",
    "print('---')\n",
    "print('constituency parse of first sentence')\n",
    "constituency_parse = sentence.parseTree\n",
    "print(constituency_parse)\n",
    "\n",
    "# get the first subtree of the constituency parse\n",
    "print('---')\n",
    "print('first subtree of constituency parse')\n",
    "print(constituency_parse.child[0])\n",
    "\n",
    "# get the value of the first subtree\n",
    "print('---')\n",
    "print('value of first subtree of constituency parse')\n",
    "print(constituency_parse.child[0].value)\n",
    "\n",
    "# get the dependency parse of the first sentence\n",
    "print('---')\n",
    "print('dependency parse of first sentence')\n",
    "dependency_parse = sentence.basicDependencies\n",
    "print(dependency_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:03:33.427662Z",
     "start_time": "2019-05-28T04:03:33.410623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "first token of first sentence\n",
      "word: \"Chris\"\n",
      "pos: \"NNP\"\n",
      "value: \"Chris\"\n",
      "before: \"\"\n",
      "after: \" \"\n",
      "originalText: \"Chris\"\n",
      "ner: \"PERSON\"\n",
      "lemma: \"Chris\"\n",
      "beginChar: 0\n",
      "endChar: 5\n",
      "utterance: 0\n",
      "speaker: \"PER0\"\n",
      "tokenBeginIndex: 0\n",
      "tokenEndIndex: 1\n",
      "hasXmlContext: false\n",
      "isNewline: false\n",
      "coarseNER: \"PERSON\"\n",
      "fineGrainedNER: \"PERSON\"\n",
      "corefMentionIndex: 0\n",
      "entityMentionIndex: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the first token of the first sentence\n",
    "print('---')\n",
    "print('first token of first sentence')\n",
    "token = sentence.token[0]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:03:50.681205Z",
     "start_time": "2019-05-28T04:03:50.671337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "part of speech tag of token\n",
      "NNP\n"
     ]
    }
   ],
   "source": [
    "# get the part-of-speech tag\n",
    "print('---')\n",
    "print('part of speech tag of token')\n",
    "token.pos\n",
    "print(token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:04:00.386817Z",
     "start_time": "2019-05-28T04:04:00.376705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "named entity tag of token\n",
      "PERSON\n"
     ]
    }
   ],
   "source": [
    "# get the named entity tag\n",
    "print('---')\n",
    "print('named entity tag of token')\n",
    "print(token.ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:04:17.122526Z",
     "start_time": "2019-05-28T04:04:17.111818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "first entity mention in sentence\n",
      "sentenceIndex: 0\n",
      "tokenStartInSentenceInclusive: 0\n",
      "tokenEndInSentenceExclusive: 2\n",
      "ner: \"PERSON\"\n",
      "entityType: \"PERSON\"\n",
      "entityMentionIndex: 0\n",
      "canonicalEntityMentionIndex: 0\n",
      "entityMentionText: \"Chris Manning\"\n",
      "\n",
      "---\n",
      "coref chains for the example\n",
      "[chainID: 5\n",
      "mention {\n",
      "  mentionID: 0\n",
      "  mentionType: \"PROPER\"\n",
      "  number: \"SINGULAR\"\n",
      "  gender: \"MALE\"\n",
      "  animacy: \"ANIMATE\"\n",
      "  beginIndex: 0\n",
      "  endIndex: 2\n",
      "  headIndex: 1\n",
      "  sentenceIndex: 0\n",
      "  position: 1\n",
      "}\n",
      "mention {\n",
      "  mentionID: 2\n",
      "  mentionType: \"PROPER\"\n",
      "  number: \"SINGULAR\"\n",
      "  gender: \"MALE\"\n",
      "  animacy: \"ANIMATE\"\n",
      "  beginIndex: 0\n",
      "  endIndex: 1\n",
      "  headIndex: 0\n",
      "  sentenceIndex: 1\n",
      "  position: 1\n",
      "}\n",
      "mention {\n",
      "  mentionID: 5\n",
      "  mentionType: \"PRONOMINAL\"\n",
      "  number: \"SINGULAR\"\n",
      "  gender: \"MALE\"\n",
      "  animacy: \"ANIMATE\"\n",
      "  beginIndex: 0\n",
      "  endIndex: 1\n",
      "  headIndex: 0\n",
      "  sentenceIndex: 2\n",
      "  position: 2\n",
      "}\n",
      "representative: 0\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# get an entity mention from the first sentence\n",
    "print('---')\n",
    "print('first entity mention in sentence')\n",
    "print(sentence.mentions[0])\n",
    "\n",
    "# access the coref chain\n",
    "print('---')\n",
    "print('coref chains for the example')\n",
    "print(ann.corefChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:04:38.997698Z",
     "start_time": "2019-05-28T04:04:37.020982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tokensregex patterns to find who wrote a sentence.\n",
    "pattern = '([ner: PERSON]+) /wrote/ /an?/ []{0,3} /sentence|article/'\n",
    "matches = client.tokensregex(text, pattern)\n",
    "# sentences contains a list with matches for each sentence.\n",
    "assert len(matches[\"sentences\"]) == 3\n",
    "# length tells you whether or not there are any matches in this\n",
    "assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "# You can access matches like most regex groups.\n",
    "matches[\"sentences\"][1][\"0\"][\"text\"] == \"Chris wrote a simple sentence\"\n",
    "matches[\"sentences\"][1][\"0\"][\"1\"][\"text\"] == \"Chris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T04:32:10.482055Z",
     "start_time": "2019-05-28T04:32:09.214702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use semgrex patterns to directly find who wrote what.\n",
    "pattern = '{word:wrote} >nsubj {}=subject >dobj {}=object'\n",
    "matches = client.semgrex(text, pattern)\n",
    "# sentences contains a list with matches for each sentence.\n",
    "assert len(matches[\"sentences\"]) == 3\n",
    "# length tells you whether or not there are any matches in this\n",
    "assert matches[\"sentences\"][1][\"length\"] == 1\n",
    "# You can access matches like most regex groups.\n",
    "matches[\"sentences\"][1][\"0\"][\"text\"] == \"wrote\"\n",
    "matches[\"sentences\"][1][\"0\"][\"$subject\"][\"text\"] == \"Chris\"\n",
    "matches[\"sentences\"][1][\"0\"][\"$object\"][\"text\"] == \"sentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a set of properties with the clientâ€™s properties_cache, use key\n",
    "```python\n",
    "FRENCH_CUSTOM_PROPS = {'annotators': 'tokenize,ssplit,pos,parse', 'tokenize.language': 'fr',\n",
    "                       'pos.model': 'edu/stanford/nlp/models/pos-tagger/french/french.tagger',\n",
    "                       'parse.model': 'edu/stanford/nlp/models/lexparser/frenchFactored.ser.gz',\n",
    "                       'outputFormat': 'text'}\n",
    "\n",
    "with CoreNLPClient(annotators='tokenize,ssplit,pos') as client:\n",
    "    client.register_properties_key('fr-custom', FRENCH_CUSTOM_PROPS)\n",
    "    ann = client.annotate(text, properties_key='fr-custom')\n",
    "\n",
    "# Set request properties as a Python dictionary\n",
    "ann = client.annotate(text, properties=FRENCH_CUSTOM_PROPS)\n",
    "```\n",
    "\n",
    "Specify a StanfordCoreNLP supported language\n",
    "ann = client.annotate(text, properties='german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T06:36:31.208882Z",
     "start_time": "2019-05-28T06:36:30.940554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 1\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 2\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 3\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 4\n",
      "}\n",
      "node {\n",
      "  sentenceIndex: 0\n",
      "  index: 5\n",
      "}\n",
      "edge {\n",
      "  source: 2\n",
      "  target: 1\n",
      "  dep: \"det\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 4\n",
      "  target: 2\n",
      "  dep: \"nsubj\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 4\n",
      "  target: 3\n",
      "  dep: \"cop\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "edge {\n",
      "  source: 4\n",
      "  target: 5\n",
      "  dep: \"punct\"\n",
      "  isExtra: false\n",
      "  sourceCopy: 0\n",
      "  targetCopy: 0\n",
      "  language: UniversalEnglish\n",
      "}\n",
      "root: 4\n",
      "\n",
      "word: \".\"\n",
      "pos: \".\"\n",
      "value: \".\"\n",
      "before: \"\"\n",
      "after: \"\"\n",
      "originalText: \".\"\n",
      "ner: \"O\"\n",
      "lemma: \".\"\n",
      "beginChar: 14\n",
      "endChar: 15\n",
      "utterance: 0\n",
      "speaker: \"PER0\"\n",
      "tokenBeginIndex: 4\n",
      "tokenEndIndex: 5\n",
      "hasXmlContext: false\n",
      "isNewline: false\n",
      "coarseNER: \"O\"\n",
      "fineGrainedNER: \"O\"\n",
      "\n",
      "word: \"is\"\n",
      "pos: \"VBZ\"\n",
      "value: \"is\"\n",
      "before: \" \"\n",
      "after: \" \"\n",
      "originalText: \"is\"\n",
      "ner: \"O\"\n",
      "lemma: \"be\"\n",
      "beginChar: 8\n",
      "endChar: 10\n",
      "utterance: 0\n",
      "speaker: \"PER0\"\n",
      "tokenBeginIndex: 2\n",
      "tokenEndIndex: 3\n",
      "hasXmlContext: false\n",
      "isNewline: false\n",
      "coarseNER: \"O\"\n",
      "fineGrainedNER: \"O\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def disp_tree(text):\n",
    "    ann = client.annotate(text)\n",
    "    sentence = ann.sentence[0]\n",
    "    dependency_parse = sentence.basicDependencies\n",
    "    print(dependency_parse)\n",
    "    \n",
    "    token = sentence.token[4]\n",
    "    print(token)\n",
    "    token = sentence.token[2]\n",
    "    print(token)\n",
    "\n",
    "disp_tree('The car is red.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T06:29:56.219063Z",
     "start_time": "2019-05-28T06:29:56.211613Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
