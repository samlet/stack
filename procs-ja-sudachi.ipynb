{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:28:15.398310Z",
     "start_time": "2019-09-04T14:28:15.308710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiaofeiwu/jcloud/assets/langs/workspace/rasa/japanese/src/sudachipy/sudachipy/../resources/sudachi.json\n",
      "{\n",
      "  \"systemDict\": \"system.dic\",\n",
      "  \"characterDefinitionFile\": \"char.def\",\n",
      "  \"inputTextPlugin\": [\n",
      "    {\n",
      "      \"class\": \"com.worksap.nlp.sudachi.DefaultInputTextPlugin\"\n",
      "    }\n",
      "  ],\n",
      "  \"oovProviderPlugin\": [\n",
      "    {\n",
      "      \"class\": \"com.worksap.nlp.sudachi.MeCabOovProviderPlugin\",\n",
      "      \"charDef\": \"char.def\",\n",
      "      \"unkDef\": \"unk.def\"\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"com.worksap.nlp.sudachi.SimpleOovProviderPlugin\",\n",
      "      \"oovPOS\": [\n",
      "        \"補助記号\",\n",
      "        \"一般\",\n",
      "        \"*\",\n",
      "        \"*\",\n",
      "        \"*\",\n",
      "        \"*\"\n",
      "      ],\n",
      "      \"leftId\": 5968,\n",
      "      \"rightId\": 5968,\n",
      "      \"cost\": 3857\n",
      "    }\n",
      "  ],\n",
      "  \"pathRewritePlugin\": [\n",
      "    {\n",
      "      \"class\": \"com.worksap.nlp.sudachi.JoinNumericPlugin\",\n",
      "      \"joinKanjiNumeric\": true\n",
      "    },\n",
      "    {\n",
      "      \"class\": \"com.worksap.nlp.sudachi.JoinKatakanaOovPlugin\",\n",
      "      \"oovPOS\": [\n",
      "        \"名詞\",\n",
      "        \"普通名詞\",\n",
      "        \"一般\",\n",
      "        \"*\",\n",
      "        \"*\",\n",
      "        \"*\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "from sudachipy import config\n",
    "import json\n",
    "\n",
    "with open(config.SETTINGFILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "print(config.SETTINGFILE)\n",
    "print(json.dumps(settings, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:28:28.552632Z",
     "start_time": "2019-09-04T14:28:27.113368Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_obj = dictionary.Dictionary(settings).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:23:36.679790Z",
     "start_time": "2019-06-14T13:23:36.559389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'個人の感想です'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wakati_by_sudachi(text):\n",
    "    \"\"\"\n",
    "    sudachiを使った分かち書き\n",
    "    \"\"\"\n",
    "    mode = tokenizer.Tokenizer.SplitMode.C #モードCの一番長い形で分ける\n",
    "    results =[m.surface() for m in tokenizer_obj.tokenize(mode, text)]\n",
    "    word_list = []\n",
    "    for mrph in results:\n",
    "        if not (mrph == \"\"): #何故か分かち書きの結果として空白データ（''）ができたための省く処理\n",
    "            seikika = tokenizer_obj.tokenize(mode,mrph)[0].normalized_form() #正規化（標準化？）してなるべく言葉の揺れを無くす　e.g. 打込む → 打ち込む かつ丼 → カツ丼\n",
    "            hinsi = tokenizer_obj.tokenize(mode,seikika)[0].part_of_speech()[0]\n",
    "            if hinsi in  [\"名詞\", \"動詞\", \"形容詞\"]:  # 対象とする品詞を指定\n",
    "                word = tokenizer_obj.tokenize(mode,seikika)[0].dictionary_form()\n",
    "                word_list.append(word)\n",
    "    return \" \".join(word_list) #スペースで繋げていく\n",
    "\n",
    "wakati_by_sudachi('個人の感想です')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:33:18.145096Z",
     "start_time": "2019-09-04T14:33:18.123782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['医薬品安全管理責任者']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-granular tokenization\n",
    "# (following results are w/ `system_full.dic`\n",
    "# you may not be able to replicate this particular example w/ `system_core.dic`)\n",
    "\n",
    "\n",
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "[m.surface() for m in tokenizer_obj.tokenize(mode, \"医薬品安全管理責任者\")]\n",
    "# => ['医薬品', '安全', '管理責任者']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:33:23.808944Z",
     "start_time": "2019-09-04T14:33:23.797730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['医薬品', '安全', '管理', '責任者']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.B\n",
    "[m.surface() for m in tokenizer_obj.tokenize(mode, \"医薬品安全管理責任者\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:29:02.137994Z",
     "start_time": "2019-09-04T14:29:02.117253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['イヤクヒン', 'アンゼン', 'カンリ', 'セキニンシャ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.reading_form() for m in tokenizer_obj.tokenize(mode, \"医薬品安全管理責任者\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:40:02.164873Z",
     "start_time": "2019-09-04T14:40:02.132674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shiai ha itsu desu ka'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import icu\n",
    "tr = icu.Transliterator.createInstance('Any-Latin; Latin-ASCII').transliterate\n",
    "sents=\"試合はいつですか？\"\n",
    "sents=sents.translate({ord(i): None for i in '、。！？'})\n",
    "mode = tokenizer.Tokenizer.SplitMode.B\n",
    "' '.join([tr(m.reading_form()) for m in tokenizer_obj.tokenize(mode, sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T14:33:47.822645Z",
     "start_time": "2019-09-04T14:33:47.799284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['医薬', '品', '安全', '管理', '責任', '者']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = tokenizer.Tokenizer.SplitMode.A\n",
    "[m.surface() for m in tokenizer_obj.tokenize(mode, \"医薬品安全管理責任者\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:25:36.869497Z",
     "start_time": "2019-06-14T13:25:36.861861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'食べ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Morpheme information\n",
    "\n",
    "m = tokenizer_obj.tokenize(mode, \"食べ\")[0]\n",
    "m.surface() # => '食べ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:26:37.648515Z",
     "start_time": "2019-06-14T13:26:37.638831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['食べる', 'タベ', ['動詞', '一般', '*', '*', '下一段-バ行', '連用形-一般']]\n"
     ]
    }
   ],
   "source": [
    "print([m.dictionary_form(), # => '食べる'\n",
    "    m.reading_form(), # => 'タベ'\n",
    "    m.part_of_speech()]) # => ['動詞', '一般', '*', '*', '下一段-バ行', '連用形-一般']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:26:54.971959Z",
     "start_time": "2019-06-14T13:26:54.961421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'付属'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "\n",
    "tokenizer_obj.tokenize(mode, \"附属\")[0].normalized_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:27:01.432142Z",
     "start_time": "2019-06-14T13:27:01.411919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'サマー'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj.tokenize(mode, \"SUMMER\")[0].normalized_form()\n",
    "# => 'サマー'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:27:11.730481Z",
     "start_time": "2019-06-14T13:27:11.705181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'シミュレーション'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj.tokenize(mode, \"シュミレーション\")[0].normalized_form()\n",
    "# => 'シミュレーション'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:28:50.544024Z",
     "start_time": "2019-07-04T14:28:49.156426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-3) 東京都 ['名詞', '固有名詞', '地名', '一般', '*', '*'] 地名\n",
      "(3-4) へ ['助詞', '格助詞', '*', '*', '*', '*'] *\n",
      "(4-6) 行く ['動詞', '非自立可能', '*', '*', '五段-カ行', '終止形-一般'] *\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sudachipy import tokenizer, dictionary, config\n",
    "with open(config.SETTINGFILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    settings = json.load(f)\n",
    "tokenizer_obj = dictionary.Dictionary(settings).create()\n",
    "\n",
    "sents='東京都へ行く'\n",
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "for m in tokenizer_obj.tokenize(mode, sents):\n",
    "    print(\"(%d-%d)\"%(m.begin(), m.end()), \n",
    "          m.dictionary_form(), \n",
    "          m.part_of_speech(),\n",
    "          m.part_of_speech()[2]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:28:54.502136Z",
     "start_time": "2019-07-04T14:28:54.088021Z"
    }
   },
   "outputs": [],
   "source": [
    "from natasha.markup import format_markup_css\n",
    "class Matches(object):\n",
    "    __attributes__ = ['text', 'matches']\n",
    "\n",
    "    def __init__(self, text, matches):\n",
    "        self.text = text\n",
    "        self.matches = matches\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.matches)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.matches[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matches)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.matches)\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        spans = [(_[0],_[1]) for _ in self.matches]\n",
    "        return ''.join(format_markup_css(self.text, spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:38:01.731627Z",
     "start_time": "2019-07-04T14:38:01.718577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".markup {\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ".markup > mark {\n",
       "    padding: 0.15em;\n",
       "    border-radius: 0.25em;\n",
       "    border: 1px solid #fdf07c;\n",
       "    background: #ffffc2;\n",
       "}\n",
       "    </style><div class=\"markup tex2jax_ignore\"><mark>東京都</mark>へ行く</div>"
      ],
      "text/plain": [
       "<__main__.Matches at 0x10978e4a8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_entities(sents):\n",
    "    entities=[(m.begin(), m.end(), m.part_of_speech()[2]) \n",
    "              for m in tokenizer_obj.tokenize(mode, sents) \n",
    "              if m.part_of_speech()[2]!='*']\n",
    "    matches = sorted(entities, key=lambda _: _[0])\n",
    "    return matches\n",
    "sents='東京都へ行く'\n",
    "Matches(sents, get_entities(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:38:56.061538Z",
     "start_time": "2019-07-04T14:38:56.033304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['地名_東京都']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_segs(sents):\n",
    "    matches=get_entities(sents)\n",
    "    return [ent[2]+'_'+sents[ent[0]:ent[1]] for ent in matches]\n",
    "get_segs('東京都へ行く')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:45:17.451179Z",
     "start_time": "2019-07-04T14:45:17.438495Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_entities(sents):\n",
    "    for m in tokenizer_obj.tokenize(mode, sents):\n",
    "        print(\"(%d-%d)\"%(m.begin(), m.end()), \n",
    "              m.dictionary_form(), \n",
    "              m.part_of_speech(),\n",
    "              m.part_of_speech()[2]\n",
    "             )\n",
    "def entities_df(sents):\n",
    "    import sagas\n",
    "    rs=[]\n",
    "    for m in tokenizer_obj.tokenize(mode, sents):\n",
    "        rs.append((\"(%d-%d)\"%(m.begin(), m.end()), \n",
    "              m.dictionary_form(), \n",
    "              m.part_of_speech(),\n",
    "              m.part_of_speech()[2]\n",
    "             ))\n",
    "    return sagas.to_df(rs, ['span', 'word', 'pos', 'entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T14:45:39.213698Z",
     "start_time": "2019-07-04T14:45:38.758005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(一般_博物館)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0-2)</td>\n",
       "      <td>その</td>\n",
       "      <td>[連体詞, *, *, *, *, *]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2-5)</td>\n",
       "      <td>博物館</td>\n",
       "      <td>[名詞, 普通名詞, 一般, *, *, *]</td>\n",
       "      <td>一般</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5-6)</td>\n",
       "      <td>は</td>\n",
       "      <td>[助詞, 係助詞, *, *, *, *]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(6-8)</td>\n",
       "      <td>まだ</td>\n",
       "      <td>[副詞, *, *, *, *, *]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(8-10)</td>\n",
       "      <td>開く</td>\n",
       "      <td>[動詞, 一般, *, *, 五段-カ行, 連用形-イ音便]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(10-11)</td>\n",
       "      <td>て</td>\n",
       "      <td>[助詞, 接続助詞, *, *, *, *]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(11-12)</td>\n",
       "      <td>いる</td>\n",
       "      <td>[動詞, 非自立可能, *, *, 上一段-ア行, 連用形-一般]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(12-14)</td>\n",
       "      <td>ます</td>\n",
       "      <td>[助動詞, *, *, *, 助動詞-マス, 未然形-一般]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(14-15)</td>\n",
       "      <td>ぬ</td>\n",
       "      <td>[助動詞, *, *, *, 助動詞-ヌ, 終止形-撥音便]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(15-16)</td>\n",
       "      <td>。</td>\n",
       "      <td>[補助記号, 句点, *, *, *, *]</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      span word                                pos entity\n",
       "0    (0-2)   その               [連体詞, *, *, *, *, *]      *\n",
       "1    (2-5)  博物館            [名詞, 普通名詞, 一般, *, *, *]     一般\n",
       "2    (5-6)    は              [助詞, 係助詞, *, *, *, *]      *\n",
       "3    (6-8)   まだ                [副詞, *, *, *, *, *]      *\n",
       "4   (8-10)   開く     [動詞, 一般, *, *, 五段-カ行, 連用形-イ音便]      *\n",
       "5  (10-11)    て             [助詞, 接続助詞, *, *, *, *]      *\n",
       "6  (11-12)   いる  [動詞, 非自立可能, *, *, 上一段-ア行, 連用形-一般]      *\n",
       "7  (12-14)   ます     [助動詞, *, *, *, 助動詞-マス, 未然形-一般]      *\n",
       "8  (14-15)    ぬ     [助動詞, *, *, *, 助動詞-ヌ, 終止形-撥音便]      *\n",
       "9  (15-16)    。             [補助記号, 句点, *, *, *, *]      *"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='その博物館はまだ開いていません。'\n",
    "# print_entities(text)\n",
    "print(\"(%s)\"%'; '.join(get_segs(text)))\n",
    "entities_df(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
