{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⊕ [Linguistic Features · spaCy Usage Documentation](https://spacy.io/usage/linguistic-features#pos-tagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T06:19:51.394724Z",
     "start_time": "2019-05-31T06:19:50.630929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nsubj</td>\n",
       "      <td>apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aux</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROOT</td>\n",
       "      <td>look</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prep</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pcomp</td>\n",
       "      <td>buy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>buying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compound</td>\n",
       "      <td>u.k.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>U.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dobj</td>\n",
       "      <td>startup</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>startup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prep</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quantmod</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>compound</td>\n",
       "      <td>1</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pobj</td>\n",
       "      <td>billion</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dep    lemma    pos  tag     text\n",
       "0      nsubj    apple  PROPN  NNP    Apple\n",
       "1        aux       be   VERB  VBZ       is\n",
       "2       ROOT     look   VERB  VBG  looking\n",
       "3       prep       at    ADP   IN       at\n",
       "4      pcomp      buy   VERB  VBG   buying\n",
       "5   compound     u.k.  PROPN  NNP     U.K.\n",
       "6       dobj  startup   NOUN   NN  startup\n",
       "7       prep      for    ADP   IN      for\n",
       "8   quantmod        $    SYM    $        $\n",
       "9   compound        1    NUM   CD        1\n",
       "10      pobj  billion    NUM   CD  billion"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "def doc_df(doc):\n",
    "    toks={'text':[], 'lemma':[], 'pos':[], 'tag':[], 'dep':[]}\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                token.shape_, token.is_alpha, token.is_stop)\n",
    "        toks['text'].append(token.text)\n",
    "        toks['lemma'].append(token.lemma_)\n",
    "        toks['pos'].append(token.pos_)\n",
    "        toks['tag'].append(token.tag_)\n",
    "        toks['dep'].append(token.dep_)\n",
    "\n",
    "    df = pd.DataFrame(toks) \n",
    "    return df\n",
    "\n",
    "doc_df(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun chunks\n",
    "Noun chunks are “base noun phrases” – flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun – for example, “the lavish green grass” or “the world’s largest tech fund”. To get the noun chunks in a document, simply iterate over Doc.noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T01:09:01.364109Z",
     "start_time": "2019-05-25T01:09:01.305280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>root_dep</th>\n",
       "      <th>root_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shift</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>cars</td>\n",
       "      <td>Autonomous cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shift</td>\n",
       "      <td>dobj</td>\n",
       "      <td>liability</td>\n",
       "      <td>insurance liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toward</td>\n",
       "      <td>pobj</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>manufacturers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     head root_dep      root_text                 text\n",
       "0   shift    nsubj           cars      Autonomous cars\n",
       "1   shift     dobj      liability  insurance liability\n",
       "2  toward     pobj  manufacturers        manufacturers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "\n",
    "toks={'text':[], 'root_text':[], 'root_dep':[], 'head':[]}\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text)\n",
    "    toks['text'].append(chunk.text)\n",
    "    toks['root_text'].append(chunk.root.text)\n",
    "    toks['root_dep'].append(chunk.root.dep_)\n",
    "    toks['head'].append(chunk.root.head.text)\n",
    "df = pd.DataFrame(toks) \n",
    "df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the parse tree\n",
    "spaCy uses the terms head and child to describe the words connected by a single arc in the dependency tree. The term dep is used for the arc label, which describes the type of syntactic relation that connects the child to the head. As with other attributes, the value of .dep is a hash value. You can get the string value with .dep_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T01:10:53.797776Z",
     "start_time": "2019-05-25T01:10:53.769272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous amod cars NOUN []\n",
      "cars nsubj shift VERB [Autonomous]\n",
      "shift ROOT shift VERB [cars, liability, toward]\n",
      "insurance compound liability NOUN []\n",
      "liability dobj shift VERB [insurance]\n",
      "toward prep shift VERB [manufacturers]\n",
      "manufacturers pobj toward ADP []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the syntactic relations form a tree, every word has exactly one head. You can therefore iterate over the arcs in the tree by iterating over the words in the sentence. This is usually the best way to match an arc of interest — from below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T01:30:54.937847Z",
     "start_time": "2019-05-25T01:30:54.275110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{shift}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.symbols import nsubj, VERB\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "\n",
    "# Finding a verb with a subject from below — good\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        verbs.add(possible_subject.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T01:20:48.908228Z",
     "start_time": "2019-05-25T01:20:48.211038Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "# Since this is an interactive Jupyter environment, we can use displacy.render here\n",
    "# displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-25T01:20:56.918870Z",
     "start_time": "2019-05-25T01:20:56.229571Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "# displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:09:20.853250Z",
     "start_time": "2019-05-31T08:09:19.745478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36763\n"
     ]
    }
   ],
   "source": [
    "import resources_pb2 as res\n",
    "import protobuf_utils\n",
    "\n",
    "input_file='./data/langs/jpn_eng_spacy.data'\n",
    "load_langs = res.RsLangs()\n",
    "protobuf_utils.read_proto(load_langs, input_file)\n",
    "print(len(load_langs.langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:09:08.285905Z",
     "start_time": "2019-05-31T08:09:07.049830Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:09:29.795803Z",
     "start_time": "2019-05-31T08:09:29.713122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a password that is easy to remember but difficult to guess. ['is'] ['be']\n",
      "Choose any dress you like. ['like'] ['like']\n",
      "Choose any one from among these. [] []\n",
      "Choose friends you can rely on. ['rely'] ['rely']\n",
      "Choose one person. [] []\n",
      "Choose one. [] []\n",
      "Choose the one you like. ['like'] ['like']\n",
      "Choose whichever you like. ['like'] ['like']\n",
      "Choose whichever you want. ['want'] ['want']\n",
      "Christianity and Islam are two different religions. ['are'] ['be']\n",
      "Christmas Day is December 25th. ['is'] ['be']\n",
      "Christmas comes but once a year. ['comes'] ['come']\n",
      "Christmas fell on Saturday that year. ['fell'] ['fall']\n",
      "Christmas is December 25th. ['is'] ['be']\n",
      "Christmas is coming soon. ['coming'] ['come']\n",
      "Christmas is coming. ['coming'] ['come']\n",
      "Christmas is fast approaching. ['is'] ['be']\n",
      "Christmas is just around the corner. ['is'] ['be']\n",
      "Christmas is just two weeks from now. ['is'] ['be']\n",
      "Christmas is near at hand, isn't it? ['is', 'is'] ['be', 'be']\n",
      "Christmas is only two weeks off. ['is'] ['be']\n",
      "Christmas is soon, isn't it? ['is', 'is'] ['be', 'be']\n",
      "Christmas is soon, right? ['is'] ['be']\n",
      "Christmas is soon. ['is'] ['be']\n",
      "Cities are exciting places, but also stressful. ['are'] ['be']\n",
      "Citizens are debating about health care at City Hall. ['debating'] ['debate']\n",
      "Class doesn't begin until eight-thirty. ['begin'] ['begin']\n",
      "Classes are starting again soon. ['starting'] ['start']\n",
      "Classes start at nine o'clock every day. ['start'] ['start']\n",
      "Classical music is not my cup of tea. ['is'] ['be']\n",
      "Clean the room. [] []\n",
      "Clean the window with a damp cloth. [] []\n",
      "Clean up the room. [] []\n",
      "Clean up your room. [] []\n",
      "Clean your room. [] []\n",
      "Close the book. [] []\n",
      "Close the door after you when you leave the room. ['leave'] ['leave']\n",
      "Close the door, please. [] []\n",
      "Close the door. [] []\n",
      "Close the drawer. [] []\n",
      "Close the gate. [] []\n",
      "Close the window. [] []\n",
      "Close your book. [] []\n",
      "Close your books. [] []\n",
      "Close your eyes, please. [] []\n",
      "Close your eyes. [] []\n",
      "Cockroaches are insects. ['are'] ['be']\n",
      "Coffee keeps me awake. ['keeps'] ['keep']\n",
      "Coffee, please. [] []\n",
      "Coincidentally enough, I know him. ['know'] ['know']\n",
      "Cold winds blow hard every winter. ['blow'] ['blow']\n",
      "Cold-war tension has mounted. ['mounted'] ['mount']\n",
      "Colds are contagious. ['are'] ['be']\n",
      "Colds are prevalent this winter. ['are'] ['be']\n",
      "Columbus discovered America in 1492. ['discovered'] ['discover']\n",
      "Comb your hair before you go out. ['go'] ['go']\n",
      "Come a bit closer. [] []\n",
      "Come again tomorrow. [] []\n",
      "Come again. [] []\n",
      "Come along with me. [] []\n",
      "Come along with us. [] []\n",
      "Come along. [] []\n",
      "Come and have tea with me. [] []\n",
      "Come and help me. [] []\n",
      "Come and help us. [] []\n",
      "Come and see me any time you like. ['like'] ['like']\n",
      "Come and see me at eleven o'clock. [] []\n",
      "Come and see me on Sunday next week. [] []\n",
      "Come and see me once in a while. [] []\n",
      "Come and see me right now. [] []\n",
      "Come and see me the day after tomorrow. [] []\n",
      "Come and see me when you have time. ['have'] ['have']\n",
      "Come and see me whenever you want to. ['want'] ['want']\n",
      "Come and see me. [] []\n",
      "Come and see this. [] []\n",
      "Come and see. [] []\n",
      "Come and sit by me. [] []\n",
      "Come and visit us in Paris sometime soon. [] []\n",
      "Come anytime you like. ['like'] ['like']\n",
      "Come anytime. [] []\n",
      "Come as early as possible. [] []\n",
      "Come as soon as possible. [] []\n",
      "Come as soon as you can. ['can'] ['can']\n",
      "Come at any time you like. ['like'] ['like']\n",
      "Come at once. [] []\n",
      "Come at ten o'clock sharp. [] []\n",
      "Come back home. [] []\n",
      "Come back soon. [] []\n",
      "Come back within a month. [] []\n",
      "Come back. [] []\n",
      "Come help me. [] []\n",
      "Come here at exactly six o'clock. [] []\n",
      "Come here at precisely six o'clock. [] []\n",
      "Come here quickly. [] []\n",
      "Come here. [] []\n",
      "Come here. I want to show you something. ['want'] ['want']\n",
      "Come home as soon as you can. ['can'] ['can']\n",
      "Come home at six. [] []\n",
      "Come home before it gets dark. ['gets'] ['get']\n",
      "Come home before six. [] []\n",
      "Come home right away. [] []\n",
      "Come home. [] []\n",
      "Come in, the door's open. [] []\n",
      "Come in. [] []\n",
      "Come inside because it's cold outside. [\"'s\"] ['be']\n",
      "Come inside. [] []\n",
      "Come into my office. [] []\n",
      "Come into the room after me. [] []\n",
      "Come into the room. [] []\n",
      "Come on any day you like. ['like'] ['like']\n",
      "Come on in! [] []\n",
      "Come on in. [] []\n",
      "Come on into my office. [] []\n",
      "Come on! Give me a chance. [] []\n",
      "Come on! We'll be late. ['be'] ['be']\n",
      "Come on, Tom, think about it. [] []\n",
      "Come on, follow me. [] []\n",
      "Come on, spit it out! [] []\n",
      "Come on. [] []\n",
      "Come out with your hands up. [] []\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc\n",
    "# lang=load_langs.langs[188]\n",
    "for lang in load_langs.langs[2000:2120]:\n",
    "    doc = Doc(nlp.vocab).from_bytes(lang.store)\n",
    "    print(lang.entries[0], lang.verbs, lang.verbLemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:09:41.965186Z",
     "start_time": "2019-05-31T08:09:41.761239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36763\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "englist=[]\n",
    "for lang in load_langs.langs:\n",
    "    englist.append(lang.entries[0])\n",
    "x=np.array(englist) \n",
    "rs=np.unique(x)\n",
    "print(len(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T06:20:00.008553Z",
     "start_time": "2019-05-31T06:19:59.965014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A stitch in time saves nine\" is a proverb.\n",
      "\" \" PUNCT `` punct \" False False\n",
      "A a DET DT det X True False\n",
      "stitch stitch NOUN NN nsubj xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "time time NOUN NN pobj xxxx True False\n",
      "saves save VERB VBZ csubj xxxx True False\n",
      "nine nine NUM CD dobj xxxx True True\n",
      "\" \" PUNCT `` punct \" False False\n",
      "is be VERB VBZ ROOT xx True True\n",
      "a a DET DT det x True True\n",
      "proverb proverb NOUN NN attr xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>punct</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>``</td>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>det</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nsubj</td>\n",
       "      <td>stitch</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>stitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prep</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pobj</td>\n",
       "      <td>time</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>csubj</td>\n",
       "      <td>save</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>saves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dobj</td>\n",
       "      <td>nine</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>punct</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>``</td>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ROOT</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>det</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attr</td>\n",
       "      <td>proverb</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>proverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dep    lemma    pos  tag     text\n",
       "0   punct        \"  PUNCT   ``        \"\n",
       "1     det        a    DET   DT        A\n",
       "2   nsubj   stitch   NOUN   NN   stitch\n",
       "3    prep       in    ADP   IN       in\n",
       "4    pobj     time   NOUN   NN     time\n",
       "5   csubj     save   VERB  VBZ    saves\n",
       "6    dobj     nine    NUM   CD     nine\n",
       "7   punct        \"  PUNCT   ``        \"\n",
       "8    ROOT       be   VERB  VBZ       is\n",
       "9     det        a    DET   DT        a\n",
       "10   attr  proverb   NOUN   NN  proverb\n",
       "11  punct        .  PUNCT    .        ."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rs[0])\n",
    "doc=nlp(str(rs[0]))\n",
    "doc_df(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T07:30:51.185660Z",
     "start_time": "2019-05-31T07:30:51.175694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36763\n",
      "sampling with choices function  ['I look forward to my birthday.', \"Don't throw in the towel.\", 'There are a lot of trees around the pond.', \"I'm proud to be a part of this project.\", 'He is still very much alive.']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(len(rs))\n",
    "sampling = random.choices(rs, k=5)\n",
    "print(\"sampling with choices function \", sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:15:51.822229Z",
     "start_time": "2019-05-31T08:15:51.784148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 2D Array\n",
      "[[11 22 33]\n",
      " [44 55 66]\n",
      " [77 88 99]]\n",
      "Choose random row from 2D array\n",
      "[0 0]\n",
      "[[11 22 33]\n",
      " [11 22 33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "array = numpy.array([[11 ,22, 33], [44, 55, 66], [77, 88, 99]]) \n",
    "print(\"Printing 2D Array\")\n",
    "print(array)\n",
    "print(\"Choose random row from 2D array\")\n",
    "randomRow = numpy.random.randint(3, size=2)\n",
    "print(randomRow)\n",
    "print(array[randomRow,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T08:11:39.026728Z",
     "start_time": "2019-05-31T08:11:39.020288Z"
    }
   },
   "outputs": [],
   "source": [
    "?numpy.random.randint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
